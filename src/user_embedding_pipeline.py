#!/usr/bin/env python3
"""
User-Specific Embedding Pipeline
==================================
Her kullanÄ±cÄ±nÄ±n kendi verisi iÃ§in embedding oluÅŸturur.
KullanÄ±cÄ±lar birbirlerinin verilerini gÃ¶remez.
"""

import pandas as pd
import numpy as np
import faiss
import os
import json
from pathlib import Path
from sentence_transformers import SentenceTransformer
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class UserEmbeddingPipeline:
    """KullanÄ±cÄ±ya Ã¶zel embedding pipeline"""
    
    def __init__(self, user_id, model_name='paraphrase-multilingual-MiniLM-L12-v2', use_firebase_cache=True):
        """
        Args:
            user_id: Firebase user ID veya unique user identifier
            model_name: Embedding model adÄ±
            use_firebase_cache: Firebase Storage cache kullanÄ±lsÄ±n mÄ±?
        """
        self.user_id = user_id
        self.model_name = model_name
        self.model = None
        self.use_firebase_cache = use_firebase_cache
        
        # KullanÄ±cÄ± iÃ§in Ã¶zel klasÃ¶r - use /tmp in production (Hugging Face Spaces)
        import os
        data_base_dir = os.getenv('DATA_DIR', '/tmp' if os.getenv('SPACE_ID') else 'data')
        self.user_dir = Path(f"{data_base_dir}/user_embeddings/{user_id}")
        self.user_dir.mkdir(parents=True, exist_ok=True)
        
        # Firebase Storage Manager
        self.storage_manager = None
        if use_firebase_cache:
            try:
                from firebase_storage_manager import get_storage_manager
                self.storage_manager = get_storage_manager()
            except Exception as e:
                logger.warning(f"âš ï¸  Firebase Storage not available: {e}")
        
        logger.info(f"ğŸ”§ User Embedding Pipeline initialized for user: {user_id}")
    
    def load_model(self):
        """Embedding modelini yÃ¼kle"""
        if self.model is None:
            logger.info(f"ğŸ“¥ Loading embedding model: {self.model_name}")
            # Use /tmp for cache on Hugging Face Spaces (writeable directory)
            cache_folder = '/tmp/sentence_transformers_cache'
            os.makedirs(cache_folder, exist_ok=True)
            self.model = SentenceTransformer(self.model_name, cache_folder=cache_folder)
            logger.info("âœ… Model loaded successfully")
        return self.model
    
    def create_embeddings(self, df, text_columns=['Summary', 'Description']):
        """
        DataFrame'den embedding oluÅŸtur
        
        Args:
            df: Pandas DataFrame (kullanÄ±cÄ±nÄ±n verisi)
            text_columns: Embedding iÃ§in kullanÄ±lacak text sÃ¼tunlarÄ±
        
        Returns:
            embeddings: numpy array (N x embedding_dim)
        """
        logger.info(f"ğŸ”„ Creating embeddings for {len(df)} records...")
        logger.info(f"ğŸ“ Using columns: {text_columns}")
        
        # Model'i yÃ¼kle
        model = self.load_model()
        
        # Text'leri birleÅŸtir
        texts = []
        for _, row in df.iterrows():
            text_parts = []
            for col in text_columns:
                if col in df.columns and pd.notna(row[col]):
                    text_parts.append(str(row[col]))
            
            combined_text = '. '.join(text_parts).strip().lower()
            texts.append(combined_text if combined_text else 'empty')
        
        # Embeddings oluÅŸtur
        logger.info("ğŸ¤– Generating embeddings...")
        embeddings = model.encode(
            texts,
            batch_size=32,
            show_progress_bar=True,
            convert_to_numpy=True
        )
        
        logger.info(f"âœ… Embeddings created: {embeddings.shape}")
        
        # Kaydet
        embeddings_path = self.user_dir / "embeddings.npy"
        np.save(embeddings_path, embeddings)
        logger.info(f"ğŸ’¾ Saved embeddings to: {embeddings_path}")
        
        return embeddings
    
    def create_faiss_index(self, embeddings):
        """
        FAISS index oluÅŸtur
        
        Args:
            embeddings: numpy array
        
        Returns:
            index: FAISS index
        """
        logger.info("ğŸ”„ Creating FAISS index...")
        
        # Normalize embeddings (cosine similarity iÃ§in)
        normalized_embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)
        
        # FAISS index oluÅŸtur (Inner Product - cosine similarity)
        embedding_dim = embeddings.shape[1]
        index = faiss.IndexFlatIP(embedding_dim)
        
        # Embeddings'leri ekle
        index.add(normalized_embeddings.astype('float32'))
        
        logger.info(f"âœ… FAISS index created: {index.ntotal} vectors")
        
        # Kaydet
        index_path = self.user_dir / "faiss_index.index"
        faiss.write_index(index, str(index_path))
        logger.info(f"ğŸ’¾ Saved FAISS index to: {index_path}")
        
        return index
    
    def save_metadata(self, df, text_columns, config=None):
        """
        Metadata kaydet
        
        Args:
            df: DataFrame
            text_columns: KullanÄ±lan text sÃ¼tunlarÄ±
            config: Ek konfigÃ¼rasyon (opsiyonel)
        """
        current_time = pd.Timestamp.now().isoformat()
        metadata = {
            'user_id': self.user_id,
            'num_records': len(df),
            'recordCount': len(df),  # For compatibility
            'num_columns': len(df.columns),
            'columns': df.columns.tolist(),
            'textColumns': text_columns,  # For compatibility
            'text_columns': text_columns,
            'metadataColumns': (config or {}).get('metadataColumns', []),
            'fileName': (config or {}).get('fileName', 'uploaded_data.csv'),
            'model_name': self.model_name,
            'embedding_dim': self.model.get_sentence_embedding_dimension() if self.model else None,
            'created_at': current_time,
            'createdAt': current_time,  # For compatibility
            'config': config or {}
        }
        
        metadata_path = self.user_dir / "metadata.json"
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        
        logger.info(f"ğŸ’¾ Saved metadata to: {metadata_path}")
    
    def process(self, df, text_columns=None, config=None):
        """
        Tam pipeline: embedding + FAISS index oluÅŸtur
        
        FIREBASE CACHE SYSTEM:
        1. Firebase Storage'da artifacts varsa indir ve kullan
        2. Yoksa embedding yap ve Firebase'e upload et
        
        Args:
            df: Pandas DataFrame
            text_columns: Text sÃ¼tunlarÄ± (None ise otomatik tespit)
            config: Ek konfigÃ¼rasyon
        
        Returns:
            success: bool
        """
        try:
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸš€ Starting User Embedding Pipeline for: {self.user_id}")
            logger.info(f"{'='*60}\n")
            
            # ===== FIREBASE CACHE CHECK =====
            if self.use_firebase_cache and self.storage_manager and self.storage_manager.initialized:
                logger.info("ğŸ” Checking Firebase Storage for cached embeddings...")
                
                # Check if artifacts exist in Firebase
                artifacts_exist = self.storage_manager.check_artifacts_exist(self.user_id)
                
                if artifacts_exist:
                    logger.info("âœ… Found cached embeddings in Firebase Storage!")
                    
                    # Download artifacts from Firebase
                    download_success = self.storage_manager.download_user_artifacts(
                        self.user_id, 
                        self.user_dir
                    )
                    
                    if download_success:
                        logger.info("âœ… Successfully downloaded embeddings from Firebase!")
                        logger.info("â© Skipping embedding generation - using cached version")
                        return True
                    else:
                        logger.warning("âš ï¸  Download failed, will regenerate embeddings")
                else:
                    logger.info("ğŸ“ No cached embeddings found, will generate new ones")
            
            # ===== GENERATE NEW EMBEDDINGS =====
            # Text sÃ¼tunlarÄ±nÄ± tespit et
            if text_columns is None:
                text_columns = self._detect_text_columns(df)
            
            logger.info(f"ğŸ“Š Data shape: {df.shape}")
            logger.info(f"ğŸ“ Text columns: {text_columns}")
            
            # 1. Embeddings oluÅŸtur
            embeddings = self.create_embeddings(df, text_columns)
            
            # 2. FAISS index oluÅŸtur
            self.create_faiss_index(embeddings)
            
            # 3. Metadata kaydet
            self.save_metadata(df, text_columns, config)
            
            # 4. Upload to Firebase Storage (if enabled)
            if self.use_firebase_cache and self.storage_manager and self.storage_manager.initialized:
                logger.info("ğŸ“¤ Uploading embeddings to Firebase Storage...")
                
                upload_success = self.storage_manager.upload_user_artifacts(
                    self.user_id, 
                    self.user_dir
                )
                
                if upload_success:
                    logger.info("âœ… Embeddings cached to Firebase Storage!")
                else:
                    logger.warning("âš ï¸  Firebase upload failed, but local artifacts are saved")
            
            logger.info(f"\n{'='*60}")
            logger.info(f"âœ… Pipeline completed successfully!")
            logger.info(f"ğŸ“ Output directory: {self.user_dir}")
            logger.info(f"{'='*60}\n")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Pipeline error: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _detect_text_columns(self, df):
        """Otomatik text sÃ¼tunlarÄ±nÄ± tespit et"""
        text_keywords = ['summary', 'description', 'title', 'Ã¶zet', 'aÃ§Ä±klama', 'baÅŸlÄ±k', 'content']
        text_columns = []
        
        for col in df.columns:
            col_lower = col.lower()
            if any(keyword in col_lower for keyword in text_keywords):
                text_columns.append(col)
        
        # En az 1 sÃ¼tun bulunmalÄ±
        if not text_columns:
            # Ä°lk string sÃ¼tunu kullan
            for col in df.columns:
                if df[col].dtype == 'object':
                    text_columns.append(col)
                    if len(text_columns) >= 2:
                        break
        
        return text_columns if text_columns else [df.columns[0]]


def create_user_embeddings(user_id, df, text_columns=None, config=None):
    """
    KullanÄ±cÄ± iÃ§in embedding oluÅŸtur (helper function)
    
    Args:
        user_id: User ID
        df: DataFrame
        text_columns: Text sÃ¼tunlarÄ± (None ise otomatik)
        config: KonfigÃ¼rasyon
    
    Returns:
        success: bool
    """
    pipeline = UserEmbeddingPipeline(user_id)
    return pipeline.process(df, text_columns, config)


if __name__ == "__main__":
    # Test iÃ§in Ã¶rnek kullanÄ±m
    print("ğŸ§ª Testing User Embedding Pipeline...")
    
    # Ã–rnek veri
    test_data = pd.DataFrame({
        'Summary': ['Test bug 1', 'Test bug 2', 'Test bug 3'],
        'Description': ['Desc 1', 'Desc 2', 'Desc 3'],
        'Priority': ['High', 'Medium', 'Low']
    })
    
    # Test kullanÄ±cÄ±sÄ± iÃ§in pipeline
    success = create_user_embeddings(
        user_id='test_user_123',
        df=test_data,
        text_columns=['Summary', 'Description']
    )
    
    if success:
        print("âœ… Test successful!")
    else:
        print("âŒ Test failed!")

